<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> - Articles</title>
    <description>Data Science and AI News</description>
    <link>
    http://localhost:4000</link>
    
      
      <item>
        <title>Introducing FLUX1.1 Pro and the BFL API</title>
        
          <description>&lt;p&gt;Black Forest Labs has announced the launch of FLUX1.1 Pro, their most advanced generative model to date, alongside the beta release of the BFL API. This development aims to enhance the capabilities of creators and developers by providing faster, higher-quality image generation and customizable API options.&lt;/p&gt;

</description>
        
        <pubDate>Wed, 02 Oct 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/Flux11pro</link>
        <guid isPermaLink="true">http://localhost:4000/Flux11pro</guid>
      </item>
      
    
      
      <item>
        <title>An AI Companion for Everyone</title>
        
          <description>&lt;p&gt;This article discusses Microsoft's vision for a new AI companion, Copilot, designed to enhance human experiences by providing personalized support and assistance. With features like voice interaction and contextual understanding, Copilot aims to simplify daily tasks while prioritizing user privacy and security.&lt;/p&gt;

</description>
        
        <pubDate>Tue, 01 Oct 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/MicAICopilot</link>
        <guid isPermaLink="true">http://localhost:4000/MicAICopilot</guid>
      </item>
      
    
      
      <item>
        <title>Anaconda AI Navigator Empowering Generative AI on Desktops</title>
        
          <description>&lt;p&gt;Anaconda has launched AI Navigator, a free desktop application that allows users to securely access and run over 200 pre-trained generative AI models locally. This innovative tool aims to democratize AI access while ensuring data privacy and security for both individuals and enterprises.&lt;/p&gt;

</description>
        
        <pubDate>Tue, 01 Oct 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/AnacondaGenAI</link>
        <guid isPermaLink="true">http://localhost:4000/AnacondaGenAI</guid>
      </item>
      
    
      
      <item>
        <title>Molmo - Leading Multimodal AI</title>
        
          <description>&lt;p&gt; Molmo is a groundbreaking family of open, state-of-the-art multimodal AI models. Our top model rivals proprietary systems across both academic benchmarks and human evaluations, while our smaller models outperform competitors up to 10 times their size.&lt;/p&gt;

</description>
        
        <pubDate>Wed, 25 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/Molmo</link>
        <guid isPermaLink="true">http://localhost:4000/Molmo</guid>
      </item>
      
    
      
      <item>
        <title>Introducing Llama 3.2- A New Era of Accessible AI Models</title>
        
          <description>&lt;p&gt;Meta's latest release, Llama 3.2, builds on the success of the Llama 3.1 models and aims to make AI more accessible to developers of all levels. With a range of powerful models designed to run on edge and mobile devices, Llama 3.2 opens the door to greater innovation and responsible AI development.&lt;/p&gt;

</description>
        
        <pubDate>Wed, 25 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/Llama32</link>
        <guid isPermaLink="true">http://localhost:4000/Llama32</guid>
      </item>
      
    
      
      <item>
        <title>Meet the Assistant Editor - Your New No-Code Sidekick for Customizing Agents in LangGraph Studio!</title>
        
          <description>&lt;p&gt; &lt;a href=&quot;https://blog.langchain.dev/langgraph-studio-the-first-agent-ide/&quot;&gt;LangGraph Studio&lt;/a&gt; just got a major upgrade with the new &lt;a href=&quot;https://langchain-ai.github.io/langgraph/cloud/how-tos/assistant_versioning/?ref=blog.langchain.dev&quot;&gt;Assistant Editor&lt;/a&gt;, a tool that lets you tweak and customize LLM-powered agents without touching any code. Whether you’re a developer or a business user, this visual editor makes it a breeze to adjust agent behavior with real-time previews and built-in version control.&lt;/p&gt;

</description>
        
        <pubDate>Wed, 25 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/LangAgent</link>
        <guid isPermaLink="true">http://localhost:4000/LangAgent</guid>
      </item>
      
    
      
      <item>
        <title>Updated production-ready Gemini models, reduced 1.5 Pro pricing, increased rate limits, and more</title>
        
          <description>&lt;p&gt; Intel has announced the release of its new Xeon 6 with Performance-cores (P-cores) and Gaudi 3 AI accelerators, offering double the performance for AI and HPC workloads. These innovations deliver significant improvements in performance per watt, with optimized total cost of ownership (TCO), enabling businesses to scale AI infrastructure efficiently.&lt;/p&gt;

</description>
        
        <pubDate>Tue, 24 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/Xeon6NGaudi3</link>
        <guid isPermaLink="true">http://localhost:4000/Xeon6NGaudi3</guid>
      </item>
      
    
      
      <item>
        <title>Updated production-ready Gemini models, reduced 1.5 Pro pricing, increased rate limits, and more</title>
        
          <description>&lt;p&gt;Google has released two updated AI models, Gemini-1.5-Pro-002 and Gemini-1.5-Flash-002, featuring enhanced performance, faster outputs, and significantly reduced costs. These models improve upon the Gemini 1.5 series with a focus on text, code, and multimodal tasks, making them highly versatile and accessible for developers through &lt;a href=&quot;https://aistudio.google.com/app/prompts/new_chat?model=gemini-1.5-pro-002&quot;&gt;Google AI Studio&lt;/a&gt; and the &lt;a href=&quot;https://ai.google.dev/gemini-api/docs/models/gemini&quot;&gt;Gemini API&lt;/a&gt;.&lt;/p&gt;

</description>
        
        <pubDate>Tue, 24 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/GeminiModelsUpdate</link>
        <guid isPermaLink="true">http://localhost:4000/GeminiModelsUpdate</guid>
      </item>
      
    
      
      <item>
        <title>NVIDIA Unveils Llama 3.1-Nemotron-51B</title>
        
          <description>&lt;p&gt;NVIDIA has introduced the Llama 3.1-Nemotron-51B language model, derived from Meta’s Llama-3.1-70B, showcasing superior accuracy and efficiency. This model leverages Neural Architecture Search (NAS) to balance performance with cost, making it accessible for diverse applications on a single NVIDIA H100 GPU.&lt;/p&gt;

</description>
        
        <pubDate>Mon, 23 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/Nemotron51B</link>
        <guid isPermaLink="true">http://localhost:4000/Nemotron51B</guid>
      </item>
      
    
      
      <item>
        <title>IBM and NASA Unveil Open-Source AI Model for Weather and Climate Innovation</title>
        
          <description>&lt;p&gt;IBM and NASA have introduced a groundbreaking AI foundation model designed to address weather and climate challenges. The open-source model promises a more flexible and scalable approach, providing advanced solutions for short-term weather forecasting and long-term climate projections, available for download on Hugging Face.&lt;/p&gt;

</description>
        
        <pubDate>Mon, 23 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/IBMnNasa</link>
        <guid isPermaLink="true">http://localhost:4000/IBMnNasa</guid>
      </item>
      
    
      
      <item>
        <title>Rereading Improves Reasoning in Large Language Models</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Sat, 21 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/rereading</link>
        <guid isPermaLink="true">http://localhost:4000/rereading</guid>
      </item>
      
    
      
      <item>
        <title>Michelangelo-Long Context Evaluations Beyond Haystacks via Latent Structure Queries</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Fri, 20 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/Michelangelo</link>
        <guid isPermaLink="true">http://localhost:4000/Michelangelo</guid>
      </item>
      
    
      
      <item>
        <title>LLMs Still Can't Plan; Can LRMs? A Preliminary Evaluation of OpenAI's o1 on PlanBench</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Fri, 20 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/EvaluationOpenAIo1</link>
        <guid isPermaLink="true">http://localhost:4000/EvaluationOpenAIo1</guid>
      </item>
      
    
      
      <item>
        <title>PDLP - A Breakthrough in Large-Scale Linear Programming</title>
        
          <description>&lt;p&gt;Linear programming (LP) has been a cornerstone of optimization across various industries for decades, but traditional methods face challenges when applied to large-scale problems. PDLP, a groundbreaking first-order method-based solver, overcomes these limitations by offering improved scalability and efficiency, making it a powerful tool for solving complex LP tasks.&lt;/p&gt;

</description>
        
        <pubDate>Fri, 20 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/PDLP</link>
        <guid isPermaLink="true">http://localhost:4000/PDLP</guid>
      </item>
      
    
      
      <item>
        <title>Training Language Models to Self-Correct via Reinforcement Learning</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Thu, 19 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/SelfCorrection</link>
        <guid isPermaLink="true">http://localhost:4000/SelfCorrection</guid>
      </item>
      
    
      
      <item>
        <title>Enhancing AI Performance with Contextual Retrieval</title>
        
          <description>&lt;p&gt;This article explores the innovative approach of Contextual Retrieval, a method that enhances the performance of AI models by improving information retrieval accuracy. By combining contextual embeddings and BM25 techniques, this method significantly reduces retrieval failures, leading to better AI responses in various applications.&lt;/p&gt;

</description>
        
        <pubDate>Thu, 19 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/AntContRag</link>
        <guid isPermaLink="true">http://localhost:4000/AntContRag</guid>
      </item>
      
    
      
      <item>
        <title>Qwen2.5-Coder Technical Report</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Wed, 18 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/QwenTechRep</link>
        <guid isPermaLink="true">http://localhost:4000/QwenTechRep</guid>
      </item>
      
    
      
      <item>
        <title>Open Source Generative AI Platform by Together AI</title>
        
          <description>&lt;p&gt; &lt;a href=&quot;https://www.together.ai/&quot;&gt;Together AI&lt;/a&gt;, a leading AI acceleration cloud, is transforming the way developers and businesses design, develop, and manage generative AI applications. By focusing on open-source models like &lt;a href=&quot;https://www.llama.com/&quot;&gt;Llama&lt;/a&gt;, Together AI is enabling developers to seamlessly navigate the entire AI lifecycle with tools that are both accessible and powerful. With the launch of innovative applications like &lt;a href=&quot;https://llamacoder.together.ai/&quot;&gt;LlamaCoder&lt;/a&gt;, the company continues to push the boundaries of what open-source generative AI can achieve.&lt;/p&gt;

</description>
        
        <pubDate>Wed, 18 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/Llamacoder</link>
        <guid isPermaLink="true">http://localhost:4000/Llamacoder</guid>
      </item>
      
    
      
      <item>
        <title>Empowering YouTube creators with generative AI</title>
        
          <description>&lt;p&gt;YouTube is aiming to change that through the introduction of advanced generative AI tools that will help millions of creators realize their creative visions. By integrating cutting-edge AI models into its platform, YouTube aims to make video generation more accessible and intuitive, particularly through its YouTube Shorts feature.&lt;/p&gt;

</description>
        
        <pubDate>Wed, 18 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/EmpYoutube</link>
        <guid isPermaLink="true">http://localhost:4000/EmpYoutube</guid>
      </item>
      
    
      
      <item>
        <title>Kolmogorov-Arnold Transformer</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Mon, 16 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/KolArnoldTransformers</link>
        <guid isPermaLink="true">http://localhost:4000/KolArnoldTransformers</guid>
      </item>
      
    
      
      <item>
        <title>Runway’s Gen-3 Alpha Video-to-Video</title>
        
          <description>&lt;p&gt;Runway has officially launched its Gen-3 Alpha Video-to-Video feature, which is now available on the web for all paid plans. This tool allows users to modify existing video content using simple text prompts.&lt;/p&gt;

</description>
        
        <pubDate>Sat, 14 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/Vid2VidRunaway</link>
        <guid isPermaLink="true">http://localhost:4000/Vid2VidRunaway</guid>
      </item>
      
    
      
      <item>
        <title>Breaking reCAPTCHAv2</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Fri, 13 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/reCaptcha</link>
        <guid isPermaLink="true">http://localhost:4000/reCaptcha</guid>
      </item>
      
    
      
      <item>
        <title>DataGemma - Grounding AI in Real-World Data to Combat Hallucinations</title>
        
          <description>&lt;p&gt;Large Language Models (LLMs) have revolutionized the AI landscape by providing powerful tools for generating human-like text, answering complex questions, and assisting with tasks like summarization and code generation. However, these models sometimes produce inaccurate information with confidence, a phenomenon known as &quot;hallucination.&quot; Addressing this issue is critical for enhancing AI reliability. Enter &lt;a href=&quot;https://ai.google.dev/gemma&quot;&gt;DataGemma&lt;/a&gt;, the first open model designed to reduce hallucinations by grounding LLMs in real-world statistical data from Google’s vast &lt;a href=&quot;https://datacommons.org/&quot;&gt;Data Commons&lt;/a&gt;. This article explores how DataGemma leverages the power of trusted data sources to improve the factual accuracy and reasoning of LLMs.&lt;/p&gt;

</description>
        
        <pubDate>Thu, 12 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/GoogleDataGemma</link>
        <guid isPermaLink="true">http://localhost:4000/GoogleDataGemma</guid>
      </item>
      
    
      
      <item>
        <title>Advancing AI Reasoning - A Look at OpenAI’s o1 Model</title>
        
          <description>&lt;p&gt; Artificial intelligence notes progress almost daily in architecture as well as in problem-solving and reasoning, but OpenAI’s latest model, o1, marks a significant leap forward. Designed to excel in complex reasoning tasks, the o1 model has achieved remarkable results in competitive programming, academic benchmarks, and real-world applications. This article explores the cutting-edge capabilities of o1, from its performance in math and science challenges to its proficiency in coding and human-like reasoning.&lt;/p&gt;

</description>
        
        <pubDate>Thu, 12 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/AdvReasoning</link>
        <guid isPermaLink="true">http://localhost:4000/AdvReasoning</guid>
      </item>
      
    
      
      <item>
        <title>How Adobe Firefly is Shaping the Future of Creative Workflows</title>
        
          <description>&lt;p&gt;Since its launch in March 2023, Adobe Firefly has transformed the creative landscape by offering innovative AI-powered features that enhance design, imaging, and vector workflows. These models have become integral to Creative Cloud and Adobe Express, enabling users to generate creative assets more efficiently. Now, Adobe is expanding Firefly's capabilities into the realm of video editing, preparing to revolutionize the process for editors and filmmakers. In this article, we’ll explore the journey of Firefly so far, its growing impact on the creative community, and its potential to reshape video production.&lt;/p&gt;

</description>
        
        <pubDate>Wed, 11 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/AdobeFirefly</link>
        <guid isPermaLink="true">http://localhost:4000/AdobeFirefly</guid>
      </item>
      
    
      
      <item>
        <title>LLaMA-Omni - Seamless Speech Interaction with Large Language Models</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Tue, 10 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/LlammaOmni</link>
        <guid isPermaLink="true">http://localhost:4000/LlammaOmni</guid>
      </item>
      
    
      
      <item>
        <title>GroUSE - A Benchmark to Evaluate Evaluators in Grounded Question Answering</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Tue, 10 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/GroUSE</link>
        <guid isPermaLink="true">http://localhost:4000/GroUSE</guid>
      </item>
      
    
      
      <item>
        <title>SambaNova Launches The World's Fastest AI Platform</title>
        
          <description>&lt;p&gt; In an exciting development for AI and machine learning, &lt;a href=&quot;https://sambanova.ai&quot;&gt;SambaNova Systems&lt;/a&gt; has announced the launch of SambaNova Cloud, the world’s fastest AI inference platform. Leveraging the power of its SN40L AI chip, SambaNova Cloud delivers unmatched speed and precision, running the groundbreaking Llama 3.1 405B model at an impressive 132 tokens per second (t/s). The platform is available to developers today, offering a powerful solution for building generative AI applications with both the largest and most capable open-source models.&lt;/p&gt;

</description>
        
        <pubDate>Tue, 10 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/SambaNova</link>
        <guid isPermaLink="true">http://localhost:4000/SambaNova</guid>
      </item>
      
    
      
      <item>
        <title>Multiple datasources - Route selections</title>
        
          <description>&lt;p&gt; I hope you enjoy every step so far. Until this point of our Langchain/RAG journey, we have managed to build a simple local application and a querry transformation assistant. But what happens when we have multiple data sources? How to define where our application will retrieve the required information from? The definition of this process, finding the correct road, or better let's say finding the correct route, is called Routing.&lt;/p&gt;

</description>
        
        <pubDate>Mon, 09 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/rag3</link>
        <guid isPermaLink="true">http://localhost:4000/rag3</guid>
      </item>
      
    
      
      <item>
        <title>LLMs Will Always Hallucinate, and We Need to Live With This</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Mon, 09 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/AlwaysHallucinate</link>
        <guid isPermaLink="true">http://localhost:4000/AlwaysHallucinate</guid>
      </item>
      
    
      
      <item>
        <title>Exploring the Replit Agent - AI Power Coding for Developers</title>
        
          <description>&lt;p&gt;Replit has long been at the forefront of integrating AI into software development, and their latest offering, the &lt;strong&gt;Replit Agent&lt;/strong&gt;, is no exception. Currently available through a limited early access program, this AI-powered assistant is designed to help users create software projects from scratch using simple, natural language prompts. Whether you’re a seasoned developer or new to coding, Replit Agent aims to make building applications more intuitive and accessible.&lt;/p&gt;

</description>
        
        <pubDate>Mon, 09 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/ReplitAgent</link>
        <guid isPermaLink="true">http://localhost:4000/ReplitAgent</guid>
      </item>
      
    
      
      <item>
        <title>Google’s Illuminate - Transforming Academic Papers into AI-Generated Podcasts</title>
        
          <description>&lt;p&gt;Google Labs has a long tradition of inviting users to explore innovative technologies, with notable successes like Gmail, which began as an exclusive beta. Now, Google is unveiling Illuminate, a groundbreaking project that transforms academic papers into AI-generated audio discussions, styled like an NPR podcast. The concept is straightforward but powerful: Google's large language model, Gemini, creates a concise summary of a research paper and follows it up with a Q&amp;amp;A session. These are voiced by two AI-generated personas—a male interviewer and a female expert—who guide listeners through a brief, engaging conversation about the paper’s key points.

&lt;/p&gt;
</description>
        
        <pubDate>Mon, 09 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/GoogleIllumnate</link>
        <guid isPermaLink="true">http://localhost:4000/GoogleIllumnate</guid>
      </item>
      
    
      
      <item>
        <title>Theory, Analysis, and Best Practices for Sigmoid Self-Attention</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Fri, 06 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/SigmoidSelfAttntion</link>
        <guid isPermaLink="true">http://localhost:4000/SigmoidSelfAttntion</guid>
      </item>
      
    
      
      <item>
        <title>Open MAGVIT2 - An Open-Source Project Toward Democratizing Auto-regressive Visual Generation</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Fri, 06 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/MAGVIT2</link>
        <guid isPermaLink="true">http://localhost:4000/MAGVIT2</guid>
      </item>
      
    
      
      <item>
        <title>Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study with 100+ NLP Researchers</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Fri, 06 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/LLMNovelResearchIdeas</link>
        <guid isPermaLink="true">http://localhost:4000/LLMNovelResearchIdeas</guid>
      </item>
      
    
      
      <item>
        <title>OLMoE-Open Mixture of Experts Language Models</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Tue, 03 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/OLMoE</link>
        <guid isPermaLink="true">http://localhost:4000/OLMoE</guid>
      </item>
      
    
      
      <item>
        <title>In Defense of RAG in the Era of Long-Context Language Models</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Tue, 03 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/DefenceOfRAG</link>
        <guid isPermaLink="true">http://localhost:4000/DefenceOfRAG</guid>
      </item>
      
    
      
      <item>
        <title>FLUX that Plays Music</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Sun, 01 Sep 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/FLUXthatPlaysMusic</link>
        <guid isPermaLink="true">http://localhost:4000/FLUXthatPlaysMusic</guid>
      </item>
      
    
      
      <item>
        <title>Diffusion Models Are Real-Time Game Engines</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Tue, 27 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/DiffusionModels</link>
        <guid isPermaLink="true">http://localhost:4000/DiffusionModels</guid>
      </item>
      
    
      
      <item>
        <title>Introducing LLaVA V1.5 7B on GroqCloud</title>
        
          <description>&lt;p&gt;Introducing LLaVA v1.5 7B: The Next Level of Multimodal AI on GroqCloud&lt;/p&gt;

</description>
        
        <pubDate>Tue, 27 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/GroqLlava</link>
        <guid isPermaLink="true">http://localhost:4000/GroqLlava</guid>
      </item>
      
    
      
      <item>
        <title>Introducing Cerebras Inference - AI at Instant Speed</title>
        
          <description>&lt;p&gt; Cerebras has unveiled its new AI inference solution, claiming it to be the fastest in the world, outpacing NVIDIA GPU-based clouds by 20 times and delivering industry-leading cost efficiency.&lt;/p&gt;

</description>
        
        <pubDate>Tue, 27 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/cerebras</link>
        <guid isPermaLink="true">http://localhost:4000/cerebras</guid>
      </item>
      
    
      
      <item>
        <title>Revolutionizing Enterprise Applications with NVIDIA's NIM Agent Blueprints</title>
        
          <description>&lt;p&gt; &lt;a href=&quot;https://www.nvidia.com/en-us/ai-data-science/ai-workflows/&quot;&gt;NVIDIA's NIM Agent Blueprints&lt;/a&gt; empower enterprises to build and deploy customized generative AI applications, driving business transformation and innovation across industries.&lt;/p&gt;

</description>
        
        <pubDate>Tue, 27 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/Prototype2Prompt</link>
        <guid isPermaLink="true">http://localhost:4000/Prototype2Prompt</guid>
      </item>
      
    
      
      <item>
        <title>The Jamba 1.5 Open Model Family-The Most Powerful and Efficient Long Context Models</title>
        
          <description>&lt;p&gt; AI21 Labs has introduced the Jamba 1.5 family of models, designed to revolutionize enterprise-level AI with unmatched speed, efficiency, and quality. The models, Jamba 1.5 Mini and Jamba 1.5 Large, are built on the novel SSM-Transformer architecture, providing a massive 256K context window— the longest among open models—along with superior long-context handling and rapid processing speeds. The Jamba models are particularly suited for enterprise applications like document analysis and Retrieval Augmented Generation (RAG), excelling in both quality and cost efficiency.&lt;/p&gt;

</description>
        
        <pubDate>Thu, 22 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/JambaFamilyModels</link>
        <guid isPermaLink="true">http://localhost:4000/JambaFamilyModels</guid>
      </item>
      
    
      
      <item>
        <title>Enhancing retrieval augmented generation through drafting</title>
        
          <description>&lt;p&gt; In the evolving landscape of AI, large language models (LLMs) have become essential for generating human-like text. However, these models often struggle with accuracy, particularly when tasked with answering complex, knowledge-intensive questions. This challenge has given rise to Retrieval Augmented Generation (RAG) systems, which combine LLMs with external knowledge retrieval to improve the factual accuracy of responses. While RAG enhances accuracy, it comes with trade-offs in efficiency, especially when dealing with large amounts of retrieved data that require complex reasoning.&lt;/p&gt;

</description>
        
        <pubDate>Wed, 21 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/SpeculativeRAGGoogle</link>
        <guid isPermaLink="true">http://localhost:4000/SpeculativeRAGGoogle</guid>
      </item>
      
    
      
      <item>
        <title>NVIDIA and Mistral AI's Mistral-NeMo-Minitron 8B Model-A Leap Forward in LLM Efficiency</title>
        
          <description>&lt;p&gt; NVIDIA and Mistral AI have introduced the Mistral-NeMo-Minitron 8B model, an advanced large language model (LLM) that delivers exceptional accuracy across nine popular benchmarks. This model is a pruned and distilled version of the Mistral NeMo 12B, maintaining high performance while being significantly more efficient.&lt;/p&gt;

</description>
        
        <pubDate>Wed, 21 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/NvidiaMistalNemoMinitron</link>
        <guid isPermaLink="true">http://localhost:4000/NvidiaMistalNemoMinitron</guid>
      </item>
      
    
      
      <item>
        <title>Automating Thought of Search - A Journey Towards Soundness and Completeness</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Tue, 20 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/AutoThoughofSearch</link>
        <guid isPermaLink="true">http://localhost:4000/AutoThoughofSearch</guid>
      </item>
      
    
      
      <item>
        <title>Transfusion - Predict the Next Token and Diffuse Images with One Multi-Modal Model</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Tue, 20 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/Transfusion</link>
        <guid isPermaLink="true">http://localhost:4000/Transfusion</guid>
      </item>
      
    
      
      <item>
        <title>To Code, or Not To Code? Exploring Impact of Code in Pre-training</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Tue, 20 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/CodeNoCoode</link>
        <guid isPermaLink="true">http://localhost:4000/CodeNoCoode</guid>
      </item>
      
    
      
      <item>
        <title>Unlocking GPT-4o Fine-Tuning-A New Era for Custom AI Models</title>
        
          <description>&lt;p&gt; Today marks a significant milestone for developers as GPT-4o, a highly anticipated AI model, opens up for fine-tuning. This feature allows developers to tailor GPT-4o for specific tasks, offering enhanced performance and cost efficiency. Whether it's coding assistance or creative content generation, fine-tuning can drastically improve results with minimal data.&lt;/p&gt;

</description>
        
        <pubDate>Tue, 20 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/FineTunegpt4o</link>
        <guid isPermaLink="true">http://localhost:4000/FineTunegpt4o</guid>
      </item>
      
    
      
      <item>
        <title>Enhancing Music Recommendations with Transformers - A New Approach in YouTube Music</title>
        
          <description>&lt;p&gt; Google presents a &lt;a href=&quot;https://research.google/blog/transformers-in-music-recommendation/&quot;&gt;music recommendation ranking system&lt;/a&gt; that uses Transformer models to better understand the sequential nature of user actions based on the current user context. &lt;/p&gt;

</description>
        
        <pubDate>Fri, 16 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/GoogleMusicRec</link>
        <guid isPermaLink="true">http://localhost:4000/GoogleMusicRec</guid>
      </item>
      
    
      
      <item>
        <title>Automated Design of Agentic Systems</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Thu, 15 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/AutoDesign</link>
        <guid isPermaLink="true">http://localhost:4000/AutoDesign</guid>
      </item>
      
    
      
      <item>
        <title>California's SB 1047 - A Weakened Bill on AI Safety</title>
        
          <description>&lt;p&gt; California’s SB 1047, a bill initially aimed at preventing AI disasters, has been significantly weakened by amendments that reduce the state’s regulatory power, addressing concerns from AI firms while still holding developers liable for catastrophic events. &lt;/p&gt;

</description>
        
        <pubDate>Wed, 14 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/CaliforniaLaw</link>
        <guid isPermaLink="true">http://localhost:4000/CaliforniaLaw</guid>
      </item>
      
    
      
      <item>
        <title>Nous Research presents Hermes 3</title>
        
          <description>&lt;p&gt;Hermes 3 contains advanced long-term context retention and multi-turn conversation capability, complex roleplaying and internal monologue abilities, and enhanced agentic function-calling.&lt;/p&gt;

</description>
        
        <pubDate>Wed, 14 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/NousHermes3</link>
        <guid isPermaLink="true">http://localhost:4000/NousHermes3</guid>
      </item>
      
    
      
      <item>
        <title>Pruning and Distilling Llama 3.1</title>
        
          <description>&lt;p&gt; Structured weight pruning combined with knowledge distillation forms an effective and efficient strategy for obtaining progressively smaller language models from an initial larger sibling. &lt;/p&gt;

</description>
        
        <pubDate>Wed, 14 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/NVIDIAMInitron</link>
        <guid isPermaLink="true">http://localhost:4000/NVIDIAMInitron</guid>
      </item>
      
    
      
      <item>
        <title>Grok-2 Beta Release</title>
        
          <description>&lt;p&gt; An early preview of Grok-2 is released, a significant step forward from X.AI's previous model Grok-1.5, featuring frontier capabilities in chat, coding, and reasoning. &lt;/p&gt;

</description>
        
        <pubDate>Wed, 14 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/Grok2Beta</link>
        <guid isPermaLink="true">http://localhost:4000/Grok2Beta</guid>
      </item>
      
    
      
      <item>
        <title>Transform your mobile device to a powerfull AI Assistant with Gemini Live.</title>
        
          <description>&lt;p&gt; Gemini Live is available today to Advanced subscribers, along with conversational overlay on Android and even more connected apps. &lt;/p&gt;

</description>
        
        <pubDate>Tue, 13 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/GeminiLive</link>
        <guid isPermaLink="true">http://localhost:4000/GeminiLive</guid>
      </item>
      
    
      
      <item>
        <title>Sakana AI’s ‘AI Scientist’, Too Autonomous for Its Own Good?</title>
        
          <description>&lt;p&gt;Sakana AI, in collaboration with scientists from the University of Oxford and the University of British Columbia, has developed an artificial intelligence system that can conduct end-to-end scientific research autonomously, called 'AI-Scientist'.&lt;/p&gt;

</description>
        
        <pubDate>Tue, 13 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/AIScientist</link>
        <guid isPermaLink="true">http://localhost:4000/AIScientist</guid>
      </item>
      
    
      
      <item>
        <title>MoMa - Efficient Early-Fusion Pre-training with Mixture of Modality-Aware Experts</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Mon, 12 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/Moma</link>
        <guid isPermaLink="true">http://localhost:4000/Moma</guid>
      </item>
      
    
      
      <item>
        <title>Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Tue, 06 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/HybridRAG</link>
        <guid isPermaLink="true">http://localhost:4000/HybridRAG</guid>
      </item>
      
    
      
      <item>
        <title>Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Tue, 06 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/TransformerExplainer</link>
        <guid isPermaLink="true">http://localhost:4000/TransformerExplainer</guid>
      </item>
      
    
      
      <item>
        <title>Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Tue, 06 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/ScallingLLMTest</link>
        <guid isPermaLink="true">http://localhost:4000/ScallingLLMTest</guid>
      </item>
      
    
      
      <item>
        <title>Introducing GitHub Models</title>
        
          <description>&lt;p&gt;The rise of the AI engineer with GitHub Models–bringing the power of industry leading large and small language models to GitHub's more than 100 million users directly on GitHub.&lt;/p&gt;

</description>
        
        <pubDate>Fri, 02 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/GithubModels</link>
        <guid isPermaLink="true">http://localhost:4000/GithubModels</guid>
      </item>
      
    
      
      <item>
        <title>LangGraph Studio - The first agent IDE</title>
        
          <description>&lt;p&gt;LangGraph Studio provides a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications.&lt;/p&gt;

</description>
        
        <pubDate>Thu, 01 Aug 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/LanggraphStudio</link>
        <guid isPermaLink="true">http://localhost:4000/LanggraphStudio</guid>
      </item>
      
    
      
      <item>
        <title>Introducing the Galileo Hallucination Index - A New Benchmark for AI Accuracy</title>
        
          <description>&lt;p&gt; Hallucination is a huge issue in the field of artificial intelligence. The accuracy and reliability of AI-generated content has become increasingly important in the last few years since people tend to rely on AI more and more in an exponential pace. Galileo, a pioneering platform in AI model evaluation, has introduced the Hallucination Index, a groundbreaking tool designed to measure and mitigate AI hallucinations. This blog post explores the Hallucination Index.&lt;/p&gt;

</description>
        
        <pubDate>Wed, 31 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/HallucinationIndex</link>
        <guid isPermaLink="true">http://localhost:4000/HallucinationIndex</guid>
      </item>
      
    
      
      <item>
        <title>RAG - Query Transformation</title>
        
          <description>&lt;p&gt; Welcome back, I hope you enjoyed the &lt;a href=&quot;https://kavourei.github.io/rag1&quot;&gt;first part&lt;/a&gt; of this series where we are going to explore a portion portion of RAG tool. It is higly suggested that you take a look at all the projects of this series step by step and more importantly to code along this project. If you don't code it out you won't get it.&lt;/p&gt;

</description>
        
        <pubDate>Mon, 29 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/rag2</link>
        <guid isPermaLink="true">http://localhost:4000/rag2</guid>
      </item>
      
    
      
      <item>
        <title>Apple Intelligence Foundation Language Models</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Mon, 29 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/AppleIntelligenceFoundationLanguageModels</link>
        <guid isPermaLink="true">http://localhost:4000/AppleIntelligenceFoundationLanguageModels</guid>
      </item>
      
    
      
      <item>
        <title>Meta AI Introduces Segment Anything 2.0 - Revolutionizing Image and Video Segmentation</title>
        
          <description>&lt;p&gt;Meta AI has once again pushed the boundaries of artificial intelligence with the release of Segment Anything 2.0 or as it is published SAM2 (Segment Anything Model). This latest iteration in image segmentation technology promises to redefine how we interact with and analyze visual data. In this blog post, we shall explore the capabilities of Segment Anything 2.0, its innovative features, and its potential impact across various industries.&lt;/p&gt;

</description>
        
        <pubDate>Mon, 29 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/MetaSam2</link>
        <guid isPermaLink="true">http://localhost:4000/MetaSam2</guid>
      </item>
      
    
      
      <item>
        <title>Llama 3.1 - Most capable model to date</title>
        
          <description>&lt;p&gt;The recent release of Meta's Llama 3.1 marks a significant advancement in the field of open-source large language models (LLMs). As the first openly available model to rival top proprietary models, Llama 3.1 is set to redefine capabilities in AI, offering a range of features that enhance its usability and performance. Some of the key features are the following: &lt;/p&gt;

</description>
        
        <pubDate>Thu, 25 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/lama3_1</link>
        <guid isPermaLink="true">http://localhost:4000/lama3_1</guid>
      </item>
      
    
      
      <item>
        <title>AI achieves silver medal solving International Mathematical Olympiad problems</title>
        
          <description>&lt;h2&gt;AI Achieves Silver Medal Level in International Math Olympiad Problems: A Milestone in Computational Intelligence&lt;/h2&gt;

</description>
        
        <pubDate>Thu, 25 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/AISilverMedal</link>
        <guid isPermaLink="true">http://localhost:4000/AISilverMedal</guid>
      </item>
      
    
      
      <item>
        <title>Mistral Unveils Mistral 7B - A Cutting-Edge Language Model</title>
        
          <description>&lt;p&gt;In a significant leap for artificial intelligence, Mistral has announced the launch of Mistral 7B, a state-of-the-art language model designed to push the boundaries of what AI can achieve in natural language processing. This blog post explores the capabilities and potential impact of Mistral 7B, highlighting its innovative features and the transformative possibilities it offers.&lt;/p&gt;

</description>
        
        <pubDate>Wed, 24 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/MistralLarge2</link>
        <guid isPermaLink="true">http://localhost:4000/MistralLarge2</guid>
      </item>
      
    
      
      <item>
        <title>KAN or MLP - A Fairer Comparison</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Tue, 23 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/KANorMLP</link>
        <guid isPermaLink="true">http://localhost:4000/KANorMLP</guid>
      </item>
      
    
      
      <item>
        <title>Introduction to RAG models</title>
        
          <description>&lt;p&gt; Firstly, in case you don't know what is RAG here is an unofficial explanation. Imagine you’re on a treasure hunt, but instead of a dusty old map, you’ve got a genius guide who knows every hidden corner. That’s RAG, short for &lt;strong&gt;Retrieval-Augmented Generation&lt;/strong&gt;. It’s like having a super-smart friend who fetches the most relevant bits of knowledge from a massive library (the retrieval part) and then crafts a perfectly tailored response just for you (the generation part). So, if your brain is a bit like a rusty old filing cabinet, think of RAG as your personal, turbo-charged librarian who’s always got the answer before you can say &quot;Google it!&quot;&lt;/p&gt;

</description>
        
        <pubDate>Mon, 22 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/rag1</link>
        <guid isPermaLink="true">http://localhost:4000/rag1</guid>
      </item>
      
    
      
      <item>
        <title>Stretching Each Dollar- Diffusion Training from Scratch on a Micro-Budget</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Mon, 22 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/DiffusionTrainingfromScratch</link>
        <guid isPermaLink="true">http://localhost:4000/DiffusionTrainingfromScratch</guid>
      </item>
      
    
      
      <item>
        <title>Shape of Motion - 4D Reconstruction from a Single Video</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Thu, 18 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/ShapeOfMotion</link>
        <guid isPermaLink="true">http://localhost:4000/ShapeOfMotion</guid>
      </item>
      
    
      
      <item>
        <title>GPT 4o Mini - Advancing cost-efficient intelligence</title>
        
          <description>&lt;p&gt; In the official &lt;a href=&quot;https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/&quot;&gt;announcement&lt;/a&gt;, OpenAI, has introduced GPT-4o Mini, a new iteration in the GPT-4 series designed to deliver high-quality AI performance while being significantly more cost-effective. This latest model aims to make advanced AI capabilities more accessible and affordable for a wider range of applications and users.&lt;/p&gt;

</description>
        
        <pubDate>Thu, 18 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/GPT4oMini</link>
        <guid isPermaLink="true">http://localhost:4000/GPT4oMini</guid>
      </item>
      
    
      
      <item>
        <title>SpreadsheetLLM - Encoding Spreadsheets for Large Language Models</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Fri, 12 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/MicrosoftSpreadsheetLLM</link>
        <guid isPermaLink="true">http://localhost:4000/MicrosoftSpreadsheetLLM</guid>
      </item>
      
    
      
      <item>
        <title>Selective Reflection-Tuning, Student-Selected Data Recycling for LLM Instruction-Tuning</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Sun, 07 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/SelectiveReflection</link>
        <guid isPermaLink="true">http://localhost:4000/SelectiveReflection</guid>
      </item>
      
    
      
      <item>
        <title>MInference</title>
        
          <description>&lt;p&gt;&lt;q&gt; Now, you can process 1M context 10x faster in a single A100 using Long-context LLMs like LLaMA-3-8B-1M, GLM-4-1M, with even better accuracy, try MInference 1.0 right now!&lt;/q&gt; as stated in the announcement.&lt;/p&gt;

</description>
        
        <pubDate>Sun, 07 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/MInference</link>
        <guid isPermaLink="true">http://localhost:4000/MInference</guid>
      </item>
      
    
      
      <item>
        <title>Gen-3 Alpha opened by Runway</title>
        
          <description>&lt;p&gt;As it is stated &lt;a href=&quot;https://runwayml.com/blog/introducing-gen-3-alpha/&quot;&gt;here&lt;/a&gt; &lt;q&gt;Gen-3 Alpha is the first of an upcoming series of models trained by Runway on a new infrastructure built for large-scale multimodal training. It is a major improvement in fidelity, consistency, and motion over Gen-2, and a step towards building General World Models.&lt;/q&gt;&lt;/p&gt;

</description>
        
        <pubDate>Sat, 06 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/RunwayTTV</link>
        <guid isPermaLink="true">http://localhost:4000/RunwayTTV</guid>
      </item>
      
    
      
      <item>
        <title>Gemini 1.5 Pro 2M context window</title>
        
          <description>&lt;p&gt;&lt;q&gt;Gemini 1.5 Pro 2M context window, code execution capabilities, and Gemma 2 are available today&lt;/q&gt;&lt;/p&gt;

</description>
        
        <pubDate>Sat, 06 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/GoogleAIStudio</link>
        <guid isPermaLink="true">http://localhost:4000/GoogleAIStudio</guid>
      </item>
      
    
      
      <item>
        <title>Mixture of A Million Experts</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Thu, 04 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/MixtureofAMillionExperts</link>
        <guid isPermaLink="true">http://localhost:4000/MixtureofAMillionExperts</guid>
      </item>
      
    
      
      <item>
        <title>RouteLLM-Learning to Route LLMs with Preference Data</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Mon, 01 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/RouteLLM</link>
        <guid isPermaLink="true">http://localhost:4000/RouteLLM</guid>
      </item>
      
    
      
      <item>
        <title>AI Agents That Matter</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Mon, 01 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/AIAgentsThatMatter</link>
        <guid isPermaLink="true">http://localhost:4000/AIAgentsThatMatter</guid>
      </item>
      
    
      
      <item>
        <title>Google releases Gemma 2</title>
        
          <description>&lt;p&gt;Google has introduced Gemma 2, its latest generation of open AI models, aimed at enhancing research and development in artificial intelligence. With 9B and 27B parameter versions, Gemma 2 boasts significant improvements in performance and efficiency, making it cost-effective to deploy on common hardware like NVIDIA GPUs. The model is designed for seamless integration with existing AI tools and frameworks, ensuring swift and efficient inference processes.&lt;/p&gt;

</description>
        
        <pubDate>Thu, 27 Jun 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/Gemma2</link>
        <guid isPermaLink="true">http://localhost:4000/Gemma2</guid>
      </item>
      
    
      
      <item>
        <title>Data curation via joint example selection further accelerates multimodal learning</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Tue, 25 Jun 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/DataCuration</link>
        <guid isPermaLink="true">http://localhost:4000/DataCuration</guid>
      </item>
      
    
      
      <item>
        <title>Connecting the Dots - LLMs can Infer and Verbalize Latent Structure from Disparate Training Data</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Thu, 20 Jun 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/ConnectDots</link>
        <guid isPermaLink="true">http://localhost:4000/ConnectDots</guid>
      </item>
      
    
      
      <item>
        <title>Meta releases New AI Research Models to Accelerate Innovation at Scale</title>
        
          <description>&lt;p&gt; For over a decade, Meta's Fundamental AI Research (FAIR) team has been dedicated to advancing AI through open research. In light of rapid innovations in the field, we recognize that collaboration with the global AI community is more crucial than ever. &lt;/p&gt;

</description>
        
        <pubDate>Tue, 18 Jun 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/MetaNewAI</link>
        <guid isPermaLink="true">http://localhost:4000/MetaNewAI</guid>
      </item>
      
    
      
      <item>
        <title>NVIDIA announced Nemotron 340B</title>
        
          <description>&lt;p&gt;Nemotron-4 340B, a family of models optimized for NVIDIA NeMo and NVIDIA TensorRT-LLM, includes cutting-edge instruct and reward models, and a dataset for generative AI training.&lt;/p&gt;

</description>
        
        <pubDate>Fri, 14 Jun 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/NVIDIARelease</link>
        <guid isPermaLink="true">http://localhost:4000/NVIDIARelease</guid>
      </item>
      
    
      
      <item>
        <title>Google open Project</title>
        
          <description>&lt;p&gt;During the Google I/O 2024 developer conference, Google revealed that Project IDX, its next-generation, AI-powered browser-based development environment, is now in open beta. Initially introduced in August as an invite-only service, Project IDX has already been tested by over 100,000 developers.&lt;/p&gt;

</description>
        
        <pubDate>Fri, 14 Jun 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/GoogleProjectIDX</link>
        <guid isPermaLink="true">http://localhost:4000/GoogleProjectIDX</guid>
      </item>
      
    
      
      <item>
        <title>Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B</title>
        
          <description>&lt;p&gt; &lt;a href=&quot;https://arxiv.org/abs/2406.07394&quot;&gt;Monte Carlo Trees&lt;/a&gt; with Llama-3 8B solve mathematics limitations of LLMs&lt;/p&gt;

</description>
        
        <pubDate>Thu, 13 Jun 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/MonteCarloTrees</link>
        <guid isPermaLink="true">http://localhost:4000/MonteCarloTrees</guid>
      </item>
      
    
      
      <item>
        <title>Depth Anything V2</title>
        
          <description>&lt;p&gt; &lt;a href=&quot;https://arxiv.org/abs/2406.07522&quot;&gt;Samba&lt;/a&gt; architecture achieves 3.73x faster throughput with enhanced context&lt;/p&gt;

</description>
        
        <pubDate>Thu, 13 Jun 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/DepthAnythingV2</link>
        <guid isPermaLink="true">http://localhost:4000/DepthAnythingV2</guid>
      </item>
      
    
      
      <item>
        <title>Samba - Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling</title>
        
          <description>&lt;p&gt; &lt;a href=&quot;https://arxiv.org/abs/2406.07522&quot;&gt;Samba&lt;/a&gt; architecture achieves 3.73x faster throughput with enhanced context&lt;/p&gt;

</description>
        
        <pubDate>Tue, 11 Jun 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/Samba</link>
        <guid isPermaLink="true">http://localhost:4000/Samba</guid>
      </item>
      
    
      
      <item>
        <title>Apple announced partnership with ChatGPT</title>
        
          <description>&lt;p&gt;Apple is partnering with OpenAI to put ChatGPT into Siri, the company announced at its WWDC 2024 keynote on 10th of June 2024.&lt;/p&gt;

</description>
        
        <pubDate>Mon, 10 Jun 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/AppleGPT</link>
        <guid isPermaLink="true">http://localhost:4000/AppleGPT</guid>
      </item>
      
    
      
      <item>
        <title>Anthropic's now lets you create bots to work for you and interact with external APIs and tools</title>
        
          <description>&lt;p&gt; &lt;a href=&quot;https://www.anthropic.com/news/tool-use-ga&quot;&gt;Tool use&lt;/a&gt;, which enables Claude to interact with external tools and APIs, is now generally available across the entire Claude 3 model family on the Anthropic Messages API, Amazon Bedrock, and Google Cloud's Vertex AI. With tool use, Claude can perform tasks, manipulate data, and provide more dynamic—and accurate—responses.&lt;/p&gt;

</description>
        
        <pubDate>Thu, 30 May 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/AnthropicBots</link>
        <guid isPermaLink="true">http://localhost:4000/AnthropicBots</guid>
      </item>
      
    
      
      <item>
        <title>Microsoft unveils Copilot + PCs, new Phi-3 models + Vision</title>
        
          <description>&lt;p&gt;As stated &lt;a href=&quot;https://ai.azure.com/explore/models/Phi-3-vision-128k-instruct/version/2/registry/azureml?tid=c2beb3f8-6ade-48ce-8e7d-6be943f1fbf7#overview&quot;&gt;here&lt;/a&gt;:

&lt;/p&gt;
</description>
        
        <pubDate>Thu, 23 May 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/MicrosoftAnnouncementsCopilot</link>
        <guid isPermaLink="true">http://localhost:4000/MicrosoftAnnouncementsCopilot</guid>
      </item>
      
    
      
      <item>
        <title>Paragon changes RAG model for your customers</title>
        
          <description>&lt;p&gt; &lt;i&gt;Integrate your multi-tenant AI SaaS with 100+ 3rd party apps with 70% less engineering.&lt;/i&gt;

&lt;/p&gt;
</description>
        
        <pubDate>Wed, 22 May 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/paragon</link>
        <guid isPermaLink="true">http://localhost:4000/paragon</guid>
      </item>
      
    
      
      <item>
        <title>Chameleon - Mixed-Modal Early-Fusion Foundation Models</title>
        
          <description>&lt;p&gt; &lt;a href=&quot;https://arxiv.org/abs/2405.09818&quot;&gt;Chameleon&lt;/a&gt; integrates images and text, achieving state-of-the-art performance. &lt;/p&gt;

</description>
        
        <pubDate>Thu, 16 May 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/Chameleon</link>
        <guid isPermaLink="true">http://localhost:4000/Chameleon</guid>
      </item>
      
    
      
      <item>
        <title>CAT3D - Create Anything in 3D with Multi-View Diffusion Models</title>
        
          <description>&lt;p&gt; &lt;a href=&quot;https://arxiv.org/abs/2405.10314&quot;&gt;CAT3D&lt;/a&gt; generates high-quality 3D content quickly with multi-view diffusion models. &lt;/p&gt;

</description>
        
        <pubDate>Thu, 16 May 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/CAT3D</link>
        <guid isPermaLink="true">http://localhost:4000/CAT3D</guid>
      </item>
      
    
      
      <item>
        <title>Grok comes to Europe</title>
        
          <description>&lt;p&gt; It has been announced that Grok AI model has expanded to Europe. &lt;/p&gt;

</description>
        
        <pubDate>Thu, 16 May 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/GrokToEurope</link>
        <guid isPermaLink="true">http://localhost:4000/GrokToEurope</guid>
      </item>
      
    
      
      <item>
        <title>Chatgpt new features announcements</title>
        
          <description>&lt;p&gt;OpenAI is taking AI capabilities to another level with its new ChatGPT feature. This new update enhances the user experience by allowing ChatGPT to interact with tables, charts, and add files directly from Google Drive and Microsoft OneDrive.&lt;/p&gt;

</description>
        
        <pubDate>Thu, 16 May 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/ChatTablesCharts</link>
        <guid isPermaLink="true">http://localhost:4000/ChatTablesCharts</guid>
      </item>
      
    
      
      <item>
        <title>LoRA Learns Less and Forgets Less</title>
        
          <description>&lt;p&gt; &lt;a href=&quot;https://arxiv.org/abs/2405.09673&quot;&gt;LoRA&lt;/a&gt; compared to full finetuning, shows strong regularization effects.. &lt;/p&gt;

</description>
        
        <pubDate>Wed, 15 May 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/LoRA</link>
        <guid isPermaLink="true">http://localhost:4000/LoRA</guid>
      </item>
      
    
      
      <item>
        <title>Google Announcements</title>
        
          <description>&lt;p&gt;Just a day after OpenAI wowed us with GPT-4o, Google decided it’s their turn to dazzle! Let's dive into the goodies unveiled at the Google IO conference. &lt;/p&gt;

</description>
        
        <pubDate>Tue, 14 May 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/VeoAstraGemini</link>
        <guid isPermaLink="true">http://localhost:4000/VeoAstraGemini</guid>
      </item>
      
    
      
      <item>
        <title>Jingle or No Jingle. A Hilariously Serious Dive into PyTorch Image Classification for Santa Claus Detection. 🎄</title>
        
          <description>&lt;p&gt; Season's Greetings, data scientists and tech enthusiasts! In the spirit of ho-ho-hilarity and cutting-edge Christmas cheer, I present to you a Christmas-themed trip into the world of PyTorch image classification. Armed with the power of pixels and powered by the magic of MacOS, this jolly project endeavors to answer the age-old question: Is Santa Claus photo bombing your holiday snapshots? Join me on this merry adventure and get ready for a sleigh ride through code, Christmas spirit, and a dash of high-tech merriment! &lt;/p&gt;
&lt;p&gt; Before we dive into the jingle of PyTorch and the festive magic of image classification, let's address the elephant in the room – a.k.a. the neural network. If you're already familiar with the ins and outs of neural networks, fantastic! If not, take a brief pause and explore the basics in this &lt;a href=&quot;/&quot;&gt;introductory post&lt;/a&gt;. Fear not! I won't be unwrapping the intricacies of neural network structures here. Instead, we're keeping it as simple as Santa's route to your chimney, because after all, his visit is just around the corner! &lt;/p&gt;

</description>
        
        <pubDate>Tue, 26 Dec 2023 00:00:00 +0200</pubDate>
        <link>
        http://localhost:4000/jingle_or_no_jingle</link>
        <guid isPermaLink="true">http://localhost:4000/jingle_or_no_jingle</guid>
      </item>
      
    
      
      <item>
        <title>Uncovering Topics in BBC News with Latent Dirichlet Allocation in R</title>
        
          <description>&lt;p&gt; Welcome everyone! Keeping in mind the post about Latent Dirichlet Allocation (in case you have not read it yet and you are interested, you can read it &lt;a href=&quot;/the-editor/&quot;&gt;here&lt;/a&gt;), I am going explore the computational part with you on a dataset containing BBC News (you can find the corresponding data &lt;a href=&quot;/the-editor/&quot;&gt;here&lt;/a&gt;). With the assistance of R-programming language, we are going to find an optimal number of topics, in which we can cluster BBC News and tidy the archived collection of BBC News we have in our dataset. &lt;/p&gt;

</description>
        
        <pubDate>Tue, 17 Oct 2023 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/LDA_R</link>
        <guid isPermaLink="true">http://localhost:4000/LDA_R</guid>
      </item>
      
    
      
      <item>
        <title>Topic Modelling - Latent Dirichlet Allocation</title>
        
          <description>&lt;p&gt; Hello everyone! In this post I am going to go through an NLP subject. As you may have already read in this post's title, Topic Modelling is what I aim to explain to you as simple as possible. The reason for creating this post is due to the fact that I have searched around and it took me quite a while to find a non academic explanation of this subject, and I had to combine multiple sources to clearly understand what is going on with that topic. As a result, here I aim to gather all the information I found useful and try to explain everything as non-academic as possible. &lt;/p&gt;

</description>
        
        <pubDate>Thu, 05 Oct 2023 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/lda_fundamentals</link>
        <guid isPermaLink="true">http://localhost:4000/lda_fundamentals</guid>
      </item>
      
    
      
      <item>
        <title>Neural Network ~ Predicting a Numerical Value</title>
        
          <description>&lt;p&gt;Welcome back! As part of this introductory series on Neural Networks, we will be exploring the process of building NNs and making decisions about their topology. This includes determining the number of layers, the number of neurons per layer, selecting appropriate activation functions, and implementing backpropagation. Throughout this process, we will delve into various factors to consider when building an effective neural network. Though everything is statistics (😉) I will try to keep statistical formulas to the minimum possible level.&lt;/p&gt;

</description>
        
        <pubDate>Sat, 04 Mar 2023 00:00:00 +0200</pubDate>
        <link>
        http://localhost:4000/neural_network</link>
        <guid isPermaLink="true">http://localhost:4000/neural_network</guid>
      </item>
      
    
      
      <item>
        <title>A smooth introduction to Neural Networks</title>
        
          <description>&lt;h2 id=&quot;specialformatting&quot;&gt;Introduction&lt;/h2&gt;

</description>
        
        <pubDate>Thu, 09 Feb 2023 00:00:00 +0200</pubDate>
        <link>
        http://localhost:4000/neural_network_intro</link>
        <guid isPermaLink="true">http://localhost:4000/neural_network_intro</guid>
      </item>
      
    
      
      <item>
        <title>Deep Learning Interviews - Hundreds of fully solved job interview questions from a wide range of key topics in AI</title>
        
          <description>&lt;p&gt; Deep Learning Interview: the best preparation book for AI/ML job seekers and students. Free on &lt;a href=&quot;https://arxiv.org/abs/2201.00650&quot;&gt;ArXiv&lt;/a&gt;.&lt;/p&gt;

</description>
        
        <pubDate>Tue, 04 Jan 2022 00:00:00 +0200</pubDate>
        <link>
        http://localhost:4000/DLInterview</link>
        <guid isPermaLink="true">http://localhost:4000/DLInterview</guid>
      </item>
      
    
  </channel>
</rss>
