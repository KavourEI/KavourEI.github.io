<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> - Articles</title>
    <description>Data Science and AI News</description>
    <link>
    http://localhost:4000</link>
    
      
      <item>
        <title>Llama 3.1 - Most capable model to date</title>
        
          <description>&lt;p&gt;The recent release of Meta's Llama 3.1 marks a significant advancement in the field of open-source large language models (LLMs). As the first openly available model to rival top proprietary models, Llama 3.1 is set to redefine capabilities in AI, offering a range of features that enhance its usability and performance. Some of the key features are the following: &lt;/p&gt;

</description>
        
        <pubDate>Thu, 25 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/lama3_1</link>
        <guid isPermaLink="true">http://localhost:4000/lama3_1</guid>
      </item>
      
    
      
      <item>
        <title>Introduction to RAG models</title>
        
          <description>&lt;p&gt; Firstly, in case you don't know what is RAG here is an unofficial explanation. Imagine you’re on a treasure hunt, but instead of a dusty old map, you’ve got a genius guide who knows every hidden corner. That’s RAG, short for &lt;strong&gt;Retrieval-Augmented Generation&lt;/strong&gt;. It’s like having a super-smart friend who fetches the most relevant bits of knowledge from a massive library (the retrieval part) and then crafts a perfectly tailored response just for you (the generation part). So, if your brain is a bit like a rusty old filing cabinet, think of RAG as your personal, turbo-charged librarian who’s always got the answer before you can say &quot;Google it!&quot;&lt;/p&gt;

</description>
        
        <pubDate>Mon, 22 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/rag1</link>
        <guid isPermaLink="true">http://localhost:4000/rag1</guid>
      </item>
      
    
      
      <item>
        <title>GPT 4o Mini - Advancing cost-efficient intelligence</title>
        
          <description>&lt;p&gt; In the official &lt;a href=&quot;https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/&quot;&gt;announcement&lt;/a&gt;, OpenAI, has introduced GPT-4o Mini, a new iteration in the GPT-4 series designed to deliver high-quality AI performance while being significantly more cost-effective. This latest model aims to make advanced AI capabilities more accessible and affordable for a wider range of applications and users.&lt;/p&gt;

</description>
        
        <pubDate>Thu, 18 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/GPT4oMini</link>
        <guid isPermaLink="true">http://localhost:4000/GPT4oMini</guid>
      </item>
      
    
      
      <item>
        <title>SpreadsheetLLM - Encoding Spreadsheets for Large Language Models</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Fri, 12 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/MicrosoftSpreadsheetLLM</link>
        <guid isPermaLink="true">http://localhost:4000/MicrosoftSpreadsheetLLM</guid>
      </item>
      
    
      
      <item>
        <title>MInference</title>
        
          <description>&lt;p&gt;&lt;q&gt; Now, you can process 1M context 10x faster in a single A100 using Long-context LLMs like LLaMA-3-8B-1M, GLM-4-1M, with even better accuracy, try MInference 1.0 right now!&lt;/q&gt; as stated in the announcement.&lt;/p&gt;

</description>
        
        <pubDate>Sun, 07 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/MInference</link>
        <guid isPermaLink="true">http://localhost:4000/MInference</guid>
      </item>
      
    
      
      <item>
        <title>Gen-3 Alpha opened by Runway</title>
        
          <description>&lt;p&gt;As it is stated &lt;a href=&quot;https://runwayml.com/blog/introducing-gen-3-alpha/&quot;&gt;here&lt;/a&gt; &lt;q&gt;Gen-3 Alpha is the first of an upcoming series of models trained by Runway on a new infrastructure built for large-scale multimodal training. It is a major improvement in fidelity, consistency, and motion over Gen-2, and a step towards building General World Models.&lt;/q&gt;&lt;/p&gt;

</description>
        
        <pubDate>Sat, 06 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/RunwayTTV</link>
        <guid isPermaLink="true">http://localhost:4000/RunwayTTV</guid>
      </item>
      
    
      
      <item>
        <title>Gemini 1.5 Pro 2M context window</title>
        
          <description>&lt;p&gt;&lt;q&gt;Gemini 1.5 Pro 2M context window, code execution capabilities, and Gemma 2 are available today&lt;/q&gt;&lt;/p&gt;

</description>
        
        <pubDate>Sat, 06 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/GoogleAIStudio</link>
        <guid isPermaLink="true">http://localhost:4000/GoogleAIStudio</guid>
      </item>
      
    
      
      <item>
        <title>RouteLLM-Learning to Route LLMs with Preference Data</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Mon, 01 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/RouteLLM</link>
        <guid isPermaLink="true">http://localhost:4000/RouteLLM</guid>
      </item>
      
    
      
      <item>
        <title>AI Agents That Matter</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Mon, 01 Jul 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/AIAgentsThatMatter</link>
        <guid isPermaLink="true">http://localhost:4000/AIAgentsThatMatter</guid>
      </item>
      
    
      
      <item>
        <title>Google releases Gemma 2</title>
        
          <description>&lt;p&gt;Google has introduced Gemma 2, its latest generation of open AI models, aimed at enhancing research and development in artificial intelligence. With 9B and 27B parameter versions, Gemma 2 boasts significant improvements in performance and efficiency, making it cost-effective to deploy on common hardware like NVIDIA GPUs. The model is designed for seamless integration with existing AI tools and frameworks, ensuring swift and efficient inference processes.&lt;/p&gt;

</description>
        
        <pubDate>Thu, 27 Jun 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/Gemma2</link>
        <guid isPermaLink="true">http://localhost:4000/Gemma2</guid>
      </item>
      
    
      
      <item>
        <title>Data curation via joint example selection further accelerates multimodal learning</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Tue, 25 Jun 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/DataCuration</link>
        <guid isPermaLink="true">http://localhost:4000/DataCuration</guid>
      </item>
      
    
      
      <item>
        <title>Connecting the Dots - LLMs can Infer and Verbalize Latent Structure from Disparate Training Data</title>
        
          <description>&lt;h2&gt; Abstract &lt;/h2&gt;

</description>
        
        <pubDate>Thu, 20 Jun 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/ConnectDots</link>
        <guid isPermaLink="true">http://localhost:4000/ConnectDots</guid>
      </item>
      
    
      
      <item>
        <title>Meta releases New AI Research Models to Accelerate Innovation at Scale</title>
        
          <description>&lt;p&gt; For over a decade, Meta's Fundamental AI Research (FAIR) team has been dedicated to advancing AI through open research. In light of rapid innovations in the field, we recognize that collaboration with the global AI community is more crucial than ever. &lt;/p&gt;

</description>
        
        <pubDate>Tue, 18 Jun 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/MetaNewAI</link>
        <guid isPermaLink="true">http://localhost:4000/MetaNewAI</guid>
      </item>
      
    
      
      <item>
        <title>NVIDIA announced Nemotron 340B</title>
        
          <description>&lt;p&gt;Nemotron-4 340B, a family of models optimized for NVIDIA NeMo and NVIDIA TensorRT-LLM, includes cutting-edge instruct and reward models, and a dataset for generative AI training.&lt;/p&gt;

</description>
        
        <pubDate>Fri, 14 Jun 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/NVIDIARelease</link>
        <guid isPermaLink="true">http://localhost:4000/NVIDIARelease</guid>
      </item>
      
    
      
      <item>
        <title>Google open Project</title>
        
          <description>&lt;p&gt;During the Google I/O 2024 developer conference, Google revealed that Project IDX, its next-generation, AI-powered browser-based development environment, is now in open beta. Initially introduced in August as an invite-only service, Project IDX has already been tested by over 100,000 developers.&lt;/p&gt;

</description>
        
        <pubDate>Fri, 14 Jun 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/GoogleProjectIDX</link>
        <guid isPermaLink="true">http://localhost:4000/GoogleProjectIDX</guid>
      </item>
      
    
      
      <item>
        <title>Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B</title>
        
          <description>&lt;p&gt; &lt;a href=&quot;https://arxiv.org/abs/2406.07394&quot;&gt;Monte Carlo Trees&lt;/a&gt; with Llama-3 8B solve mathematics limitations of LLMs&lt;/p&gt;

</description>
        
        <pubDate>Thu, 13 Jun 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/MonteCarloTrees</link>
        <guid isPermaLink="true">http://localhost:4000/MonteCarloTrees</guid>
      </item>
      
    
      
      <item>
        <title>Depth Anything V2</title>
        
          <description>&lt;p&gt; &lt;a href=&quot;https://arxiv.org/abs/2406.07522&quot;&gt;Samba&lt;/a&gt; architecture achieves 3.73x faster throughput with enhanced context&lt;/p&gt;

</description>
        
        <pubDate>Thu, 13 Jun 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/DepthAnythingV2</link>
        <guid isPermaLink="true">http://localhost:4000/DepthAnythingV2</guid>
      </item>
      
    
      
      <item>
        <title>Samba - Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling</title>
        
          <description>&lt;p&gt; &lt;a href=&quot;https://arxiv.org/abs/2406.07522&quot;&gt;Samba&lt;/a&gt; architecture achieves 3.73x faster throughput with enhanced context&lt;/p&gt;

</description>
        
        <pubDate>Tue, 11 Jun 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/Samba</link>
        <guid isPermaLink="true">http://localhost:4000/Samba</guid>
      </item>
      
    
      
      <item>
        <title>Apple announced partnership with ChatGPT</title>
        
          <description>&lt;p&gt;Apple is partnering with OpenAI to put ChatGPT into Siri, the company announced at its WWDC 2024 keynote on 10th of June 2024.&lt;/p&gt;

</description>
        
        <pubDate>Mon, 10 Jun 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/AppleGPT</link>
        <guid isPermaLink="true">http://localhost:4000/AppleGPT</guid>
      </item>
      
    
      
      <item>
        <title>Anthropic's now lets you create bots to work for you and interact with external APIs and tools</title>
        
          <description>&lt;p&gt; &lt;a href=&quot;https://www.anthropic.com/news/tool-use-ga&quot;&gt;Tool use&lt;/a&gt;, which enables Claude to interact with external tools and APIs, is now generally available across the entire Claude 3 model family on the Anthropic Messages API, Amazon Bedrock, and Google Cloud's Vertex AI. With tool use, Claude can perform tasks, manipulate data, and provide more dynamic—and accurate—responses.&lt;/p&gt;

</description>
        
        <pubDate>Thu, 30 May 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/AnthropicBots</link>
        <guid isPermaLink="true">http://localhost:4000/AnthropicBots</guid>
      </item>
      
    
      
      <item>
        <title>Microsoft unveils Copilot + PCs, new Phi-3 models + Vision</title>
        
          <description>&lt;p&gt;As stated &lt;a href=&quot;https://ai.azure.com/explore/models/Phi-3-vision-128k-instruct/version/2/registry/azureml?tid=c2beb3f8-6ade-48ce-8e7d-6be943f1fbf7#overview&quot;&gt;here&lt;/a&gt;:

&lt;/p&gt;
</description>
        
        <pubDate>Thu, 23 May 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/MicrosoftAnnouncementsCopilot</link>
        <guid isPermaLink="true">http://localhost:4000/MicrosoftAnnouncementsCopilot</guid>
      </item>
      
    
      
      <item>
        <title>Paragon changes RAG model for your customers</title>
        
          <description>&lt;p&gt; &lt;i&gt;Integrate your multi-tenant AI SaaS with 100+ 3rd party apps with 70% less engineering.&lt;/i&gt;

&lt;/p&gt;
</description>
        
        <pubDate>Wed, 22 May 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/paragon</link>
        <guid isPermaLink="true">http://localhost:4000/paragon</guid>
      </item>
      
    
      
      <item>
        <title>Chameleon - Mixed-Modal Early-Fusion Foundation Models</title>
        
          <description>&lt;p&gt; &lt;a href=&quot;https://arxiv.org/abs/2405.09818&quot;&gt;Chameleon&lt;/a&gt; integrates images and text, achieving state-of-the-art performance. &lt;/p&gt;

</description>
        
        <pubDate>Thu, 16 May 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/Chameleon</link>
        <guid isPermaLink="true">http://localhost:4000/Chameleon</guid>
      </item>
      
    
      
      <item>
        <title>CAT3D - Create Anything in 3D with Multi-View Diffusion Models</title>
        
          <description>&lt;p&gt; &lt;a href=&quot;https://arxiv.org/abs/2405.10314&quot;&gt;CAT3D&lt;/a&gt; generates high-quality 3D content quickly with multi-view diffusion models. &lt;/p&gt;

</description>
        
        <pubDate>Thu, 16 May 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/CAT3D</link>
        <guid isPermaLink="true">http://localhost:4000/CAT3D</guid>
      </item>
      
    
      
      <item>
        <title>Grok comes to Europe</title>
        
          <description>&lt;p&gt; It has been announced that Grok AI model has expanded to Europe. &lt;/p&gt;

</description>
        
        <pubDate>Thu, 16 May 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/GrokToEurope</link>
        <guid isPermaLink="true">http://localhost:4000/GrokToEurope</guid>
      </item>
      
    
      
      <item>
        <title>Chatgpt new features announcements</title>
        
          <description>&lt;p&gt;OpenAI is taking AI capabilities to another level with its new ChatGPT feature. This new update enhances the user experience by allowing ChatGPT to interact with tables, charts, and add files directly from Google Drive and Microsoft OneDrive.&lt;/p&gt;

</description>
        
        <pubDate>Thu, 16 May 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/ChatTablesCharts</link>
        <guid isPermaLink="true">http://localhost:4000/ChatTablesCharts</guid>
      </item>
      
    
      
      <item>
        <title>LoRA Learns Less and Forgets Less</title>
        
          <description>&lt;p&gt; &lt;a href=&quot;https://arxiv.org/abs/2405.09673&quot;&gt;LoRA&lt;/a&gt; compared to full finetuning, shows strong regularization effects.. &lt;/p&gt;

</description>
        
        <pubDate>Wed, 15 May 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/LoRA</link>
        <guid isPermaLink="true">http://localhost:4000/LoRA</guid>
      </item>
      
    
      
      <item>
        <title>Google Announcements</title>
        
          <description>&lt;p&gt;Just a day after OpenAI wowed us with GPT-4o, Google decided it’s their turn to dazzle! Let's dive into the goodies unveiled at the Google IO conference. &lt;/p&gt;

</description>
        
        <pubDate>Tue, 14 May 2024 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/VeoAstraGemini</link>
        <guid isPermaLink="true">http://localhost:4000/VeoAstraGemini</guid>
      </item>
      
    
      
      <item>
        <title>Jingle or No Jingle. A Hilariously Serious Dive into PyTorch Image Classification for Santa Claus Detection. 🎄</title>
        
          <description>&lt;p&gt; Season's Greetings, data scientists and tech enthusiasts! In the spirit of ho-ho-hilarity and cutting-edge Christmas cheer, I present to you a Christmas-themed trip into the world of PyTorch image classification. Armed with the power of pixels and powered by the magic of MacOS, this jolly project endeavors to answer the age-old question: Is Santa Claus photo bombing your holiday snapshots? Join me on this merry adventure and get ready for a sleigh ride through code, Christmas spirit, and a dash of high-tech merriment! &lt;/p&gt;
&lt;p&gt; Before we dive into the jingle of PyTorch and the festive magic of image classification, let's address the elephant in the room – a.k.a. the neural network. If you're already familiar with the ins and outs of neural networks, fantastic! If not, take a brief pause and explore the basics in this &lt;a href=&quot;/&quot;&gt;introductory post&lt;/a&gt;. Fear not! I won't be unwrapping the intricacies of neural network structures here. Instead, we're keeping it as simple as Santa's route to your chimney, because after all, his visit is just around the corner! &lt;/p&gt;

</description>
        
        <pubDate>Tue, 26 Dec 2023 00:00:00 +0200</pubDate>
        <link>
        http://localhost:4000/jingle_or_no_jingle</link>
        <guid isPermaLink="true">http://localhost:4000/jingle_or_no_jingle</guid>
      </item>
      
    
      
      <item>
        <title>Uncovering Topics in BBC News with Latent Dirichlet Allocation in R</title>
        
          <description>&lt;p&gt; Welcome everyone! Keeping in mind the post about Latent Dirichlet Allocation (in case you have not read it yet and you are interested, you can read it &lt;a href=&quot;/the-editor/&quot;&gt;here&lt;/a&gt;), I am going explore the computational part with you on a dataset containing BBC News (you can find the corresponding data &lt;a href=&quot;/the-editor/&quot;&gt;here&lt;/a&gt;). With the assistance of R-programming language, we are going to find an optimal number of topics, in which we can cluster BBC News and tidy the archived collection of BBC News we have in our dataset. &lt;/p&gt;

</description>
        
        <pubDate>Tue, 17 Oct 2023 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/LDA_R</link>
        <guid isPermaLink="true">http://localhost:4000/LDA_R</guid>
      </item>
      
    
      
      <item>
        <title>Topic Modelling - Latent Dirichlet Allocation</title>
        
          <description>&lt;p&gt; Hello everyone! In this post I am going to go through an NLP subject. As you may have already read in this post's title, Topic Modelling is what I aim to explain to you as simple as possible. The reason for creating this post is due to the fact that I have searched around and it took me quite a while to find a non academic explanation of this subject, and I had to combine multiple sources to clearly understand what is going on with that topic. As a result, here I aim to gather all the information I found useful and try to explain everything as non-academic as possible. &lt;/p&gt;

</description>
        
        <pubDate>Thu, 05 Oct 2023 00:00:00 +0300</pubDate>
        <link>
        http://localhost:4000/lda_fundamentals</link>
        <guid isPermaLink="true">http://localhost:4000/lda_fundamentals</guid>
      </item>
      
    
      
      <item>
        <title>Neural Network ~ Predicting a Numerical Value</title>
        
          <description>&lt;p&gt;Welcome back! As part of this introductory series on Neural Networks, we will be exploring the process of building NNs and making decisions about their topology. This includes determining the number of layers, the number of neurons per layer, selecting appropriate activation functions, and implementing backpropagation. Throughout this process, we will delve into various factors to consider when building an effective neural network. Though everything is statistics (😉) I will try to keep statistical formulas to the minimum possible level.&lt;/p&gt;

</description>
        
        <pubDate>Sat, 04 Mar 2023 00:00:00 +0200</pubDate>
        <link>
        http://localhost:4000/neural_network</link>
        <guid isPermaLink="true">http://localhost:4000/neural_network</guid>
      </item>
      
    
      
      <item>
        <title>A smooth introduction to Neural Networks</title>
        
          <description>&lt;h2 id=&quot;specialformatting&quot;&gt;Introduction&lt;/h2&gt;

</description>
        
        <pubDate>Thu, 09 Feb 2023 00:00:00 +0200</pubDate>
        <link>
        http://localhost:4000/neural_network_intro</link>
        <guid isPermaLink="true">http://localhost:4000/neural_network_intro</guid>
      </item>
      
    
      
      <item>
        <title>Deep Learning Interviews - Hundreds of fully solved job interview questions from a wide range of key topics in AI</title>
        
          <description>&lt;p&gt; Deep Learning Interview: the best preparation book for AI/ML job seekers and students. Free on &lt;a href=&quot;https://arxiv.org/abs/2201.00650&quot;&gt;ArXiv&lt;/a&gt;.&lt;/p&gt;

</description>
        
        <pubDate>Tue, 04 Jan 2022 00:00:00 +0200</pubDate>
        <link>
        http://localhost:4000/DLInterview</link>
        <guid isPermaLink="true">http://localhost:4000/DLInterview</guid>
      </item>
      
    
  </channel>
</rss>
