---
layout: post
current: post
cover:  assets/images/arxiv.jpeg
navigation: True
title: Open MAGVIT2 - An Open-Source Project Toward Democratizing Auto-regressive Visual Generation
date: 2024-09-06
tags: [research]
class: post-template
subclass: 'post'
author: Kavour
---

<h2> Abstract </h2>

<p> We present Open-MAGVIT2, a family of auto-regressive image generation models ranging from 300M to 1.5B. The Open-MAGVIT2 project produces an open-source replication of Google's MAGVIT-v2 tokenizer, a tokenizer with a super-large codebook (i.e., <math><msup><mi>2</mi><mn>18</mn></msup></math> codes), and achieves the state-of-the-art reconstruction performance (1.17 rFID) on ImageNet 256Ã—256. Furthermore, we explore its application in plain auto-regressive models and validate scalability properties. To assist auto-regressive models in predicting with a super-large vocabulary, we factorize it into two sub-vocabulary of different sizes by asymmetric token factorization, and further introduce "next sub-token prediction" to enhance sub-token interaction for better generation quality. We release all models and codes to foster innovation and creativity in the field of auto-regressive visual generation.</p>

<h2> Authors </h2>

<p> <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo,+Z">Zhuoyan Luo</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi,+F">Fengyuan Shi</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ge,+Y">Yixiao Ge</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+Y">Yujiu Yang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+L">Limin Wang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shan,+Y">Ying Shan</a></p>

<p>For more information go <a href='https://arxiv.org/abs/2409.04410'>here</a></p>