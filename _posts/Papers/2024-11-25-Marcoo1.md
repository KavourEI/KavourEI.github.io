---
layout: post
current: post
cover:  assets/images/arxiv.jpeg
navigation: True
title: Marco-o1:Towards Open Reasoning Models for Open-Ended Solutions
date: 2024-11-25
tags: [research]
class: post-templat
subclass: 'post'
author: Kavour
---

<h2> Abstract </h2>

<p> Currently OpenAI o1 sparks a surge of interest in the study of large reasoning models (LRM). Building on this momentum, Marco-o1 not only focuses on disciplines with standard answers, such as mathematics, physics, and coding -- which are well-suited for reinforcement learning (RL) -- but also places greater emphasis on open-ended resolutions. We aim to address the question: ''Can the o1 model effectively generalize to broader domains where clear standards are absent and rewards are challenging to quantify?'' Marco-o1 is powered by Chain-of-Thought (CoT) fine-tuning, Monte Carlo Tree Search (MCTS), reflection mechanisms, and innovative reasoning strategies -- optimized for complex real-world problem-solving tasks. </p>

<h2> Authors </h2>

<p> <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao,+Y" rel="nofollow">Yu Zhao</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin,+H" rel="nofollow">Huifeng Yin</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng,+B" rel="nofollow">Bo Zeng</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+H" rel="nofollow">Hao Wang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi,+T" rel="nofollow">Tianqi Shi</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lyu,+C" rel="nofollow">Chenyang Lyu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+L" rel="nofollow">Longyue Wang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo,+W" rel="nofollow">Weihua Luo</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+K" rel="nofollow">Kaifu Zhang</a> </p>

<p>For more information go <a href='https://arxiv.org/abs/2411.14405'>here</a></p>