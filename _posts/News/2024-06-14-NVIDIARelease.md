---
layout: post
current: post
cover:  assets\images\news_images\nvidia.jpg
navigation: True
title: NVIDIA announced Nemotron 340B
date: 2024-06-14
tags: [news]
class: post-template
subclass: 'post'
author: Kavour
---

<p>Nemotron-4 340B, a family of models optimized for NVIDIA NeMo and NVIDIA TensorRT-LLM, includes cutting-edge instruct and reward models, and a dataset for generative AI training.</p>

<p>NVIDIA on 14th of June, announced Nemotron-4 340B, a family of open models that developers can use to generate synthetic data for training large language models (LLMs) for commercial applications across healthcare, finance, manufacturing, retail and every other industry. </p>

<p>High-quality training data plays a critical role in the performance, accuracy and quality of responses from a custom LLM — but robust datasets can be prohibitively expensive and difficult to access. </p>

<p>Through a uniquely permissive open model license, Nemotron-4 340B gives developers a free, scalable way to generate synthetic data that can help build powerful LLMs.</p>

<p>The Nemotron-4 340B family includes base, instruct and reward models that form a pipeline to generate synthetic data used for training and refining LLMs. The models are optimized to work with NVIDIA NeMo, an open-source framework for end-to-end model training, including data curation, customization and evaluation. They’re also optimized for inference with the open-source NVIDIA TensorRT-LLM library. </p>

<p>Nemotron-4 340B can be downloaded now from the NVIDIA NGC catalog and Hugging Face. Developers will soon be able to access the models at ai.nvidia.com, where they’ll be packaged as an NVIDIA NIM microservice with a standard application programming interface that can be deployed anywhere.</p>

<p>If you want to find out more go to the <a href="https://blogs.nvidia.com/blog/nemotron-4-synthetic-data-generation-llm-training/">official blog of NVIDIA</a>.</p>